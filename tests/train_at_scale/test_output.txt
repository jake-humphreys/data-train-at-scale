============================= test session starts ==============================
platform linux -- Python 3.10.6, pytest-7.3.1, pluggy-1.0.0 -- /home/jake/.pyenv/versions/3.10.6/envs/taxifare-env/bin/python3.10
cachedir: .pytest_cache
rootdir: /home/jake/code/jake-humphreys/data-train-at-scale/tests
configfile: pytest_kitt.ini
collecting ... collected 8 items

tests/train_at_scale/test_clean.py::test_clean_data PASSED               [ 12%]
tests/train_at_scale/test_main_local.py::TestMainLocal::test_route_preprocess_and_train FAILED [ 25%]
tests/train_at_scale/test_main_local.py::TestMainLocal::test_route_pred PASSED [ 37%]
tests/train_at_scale/test_main_local.py::TestMainLocal::test_route_preprocess FAILED [ 50%]
tests/train_at_scale/test_main_local.py::TestMainLocal::test_route_train FAILED [ 62%]
tests/train_at_scale/test_model.py::test_model_can_fit PASSED            [ 75%]
tests/train_at_scale/test_notebook.py::TestNotebook::test_y_pred PASSED  [ 87%]
tests/train_at_scale/test_processor_pipeline.py::test_preprocess_features PASSED [100%]

=================================== FAILURES ===================================
________________ TestMainLocal.test_route_preprocess_and_train _________________

self = <tests.train_at_scale.test_main_local.TestMainLocal object at 0x7fb52f8fe920>

    def test_route_preprocess_and_train(self):
    
        # 1) SETUP
        data_query_path = Path(LOCAL_DATA_PATH).joinpath("raw",f"query_{MIN_DATE}_{MAX_DATE}_{DATA_SIZE}.csv")
        data_query_exists = data_query_path.is_file()
    
        if data_query_exists:
            # We start from a blank state. No cached files
            shutil.copyfile(data_query_path, f'{data_query_path}_backup')
            data_query_path.unlink()
    
        # 2) ACT
        from taxifare.interface.main_local import preprocess_and_train
    
        # Check route runs correctly
>       preprocess_and_train(min_date=MIN_DATE, max_date=MAX_DATE)

tests/train_at_scale/test_main_local.py:36: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
taxifare/interface/main_local.py:100: in preprocess_and_train
    model, history = train_model(model, X_train_processed, y_train, batch_size, patience, validation_data=(X_val_processed, y_val))
taxifare/ml_logic/model.py:84: in train_model
    history = model.fit(
../../../.pyenv/versions/3.10.6/envs/taxifare-env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70: in error_handler
    raise e.with_traceback(filtered_tb) from None
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

value = array([[0.14285714285714285, 0.0, 0.0, ..., 0.0, 0.0, 0.0],
       [0.5714285714285714, 0.0, 0.0, ..., 0.0, 0.0, 0.0],... 0.0, 0.0, 0.0],
       [0.0, 1.0, 0.0, ..., 0.0, 0.0, 0.0],
       [0.0, 0.0, 1.0, ..., 0.0, 0.0, 0.0]], dtype=object)
ctx = <tensorflow.python.eager.context.Context object at 0x7fb4bb474340>
dtype = None

    def convert_to_eager_tensor(value, ctx, dtype=None):
      """Converts the given `value` to an `EagerTensor`.
    
      Note that this function could return cached copies of created constants for
      performance reasons.
    
      Args:
        value: value to convert to EagerTensor.
        ctx: value of context.context().
        dtype: optional desired dtype of the converted EagerTensor.
    
      Returns:
        EagerTensor created from value.
    
      Raises:
        TypeError: if `dtype` is not compatible with the type of t.
      """
      if isinstance(value, ops.EagerTensor):
        if dtype is not None and value.dtype != dtype:
          raise TypeError(f"Expected tensor {value} with dtype {dtype!r}, but got "
                          f"dtype {value.dtype!r}.")
        return value
      if dtype is not None:
        try:
          dtype = dtype.as_datatype_enum
        except AttributeError:
          dtype = dtypes.as_dtype(dtype).as_datatype_enum
      ctx.ensure_initialized()
>     return ops.EagerTensor(value, ctx.device_name, dtype)
E     ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type float).

../../../.pyenv/versions/3.10.6/envs/taxifare-env/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102: ValueError
----------------------------- Captured stdout call -----------------------------
[34m
Loading TensorFlow...[0m

‚úÖ TensorFlow loaded (0.0s)
[35m
 ‚≠êÔ∏è Use case: preprocess_and_train[0m
Loading data from Querying Big Query server...
‚úÖ data cleaned
(439, 7)
(8, 7)
[34m
Preprocessing features...[0m
Index(['pickup_datetime', 'pickup_longitude', 'pickup_latitude',
       'dropoff_longitude', 'dropoff_latitude', 'passenger_count'],
      dtype='object')
‚úÖ X_processed, with shape (439, 65)
[34m
Preprocessing features...[0m
Index(['pickup_datetime', 'pickup_longitude', 'pickup_latitude',
       'dropoff_longitude', 'dropoff_latitude', 'passenger_count'],
      dtype='object')
‚úÖ X_processed, with shape (8, 65)
‚úÖ Model initialized
‚úÖ Model compiled
----------------------------- Captured stderr call -----------------------------
2023-06-05 14:44:54.178813: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-06-05 14:44:54.265791: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-05 14:44:54.269190: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2023-06-05 14:44:54.269206: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2023-06-05 14:44:54.287596: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-06-05 14:44:54.691515: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-06-05 14:44:54.691562: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-06-05 14:44:54.691565: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-06-05 14:44:57.772935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
2023-06-05 14:44:57.773038: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2023-06-05 14:44:57.773070: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory
2023-06-05 14:44:57.773094: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory
2023-06-05 14:44:57.773115: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory
2023-06-05 14:44:57.773136: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory
2023-06-05 14:44:57.773157: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory
2023-06-05 14:44:57.773176: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory
2023-06-05 14:44:57.773196: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory
2023-06-05 14:44:57.773203: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2023-06-05 14:44:57.773554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
_____________________ TestMainLocal.test_route_preprocess ______________________

self = <tests.train_at_scale.test_main_local.TestMainLocal object at 0x7fb52f8feb60>
fixture_query_1k =      fare_amount           pickup_datetime  ...  dropoff_latitude  passenger_count
0            8.9 2009-01-15 09:22:3...           4
454          8.5 2014-12-27 16:47:42+00:00  ...         40.771263                4

[455 rows x 7 columns]
fixture_processed_1k =            0    1    2    3    4    5   ...   60   61   62   63   64         65
0    0.000000  0.0  0.0  0.0  1.0  0.0...0.0   6.500000
446  0.428571  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0   8.500000

[447 rows x 66 columns]

    def test_route_preprocess(self, fixture_query_1k: pd.DataFrame, fixture_processed_1k: pd.DataFrame):
>       from taxifare.interface.main_local import preprocess
E       ImportError: cannot import name 'preprocess' from 'taxifare.interface.main_local' (/home/jake/code/jake-humphreys/data-train-at-scale/taxifare/interface/main_local.py)

tests/train_at_scale/test_main_local.py:67: ImportError
________________________ TestMainLocal.test_route_train ________________________

self = <tests.train_at_scale.test_main_local.TestMainLocal object at 0x7fb52f8feb00>

    def test_route_train(self):
    
        # SETUP
        data_processed_path = Path(LOCAL_DATA_PATH).joinpath("processed",f"processed_{MIN_DATE}_{MAX_DATE}_{DATA_SIZE}.csv")
        data_processed_exists = data_processed_path.is_file()
        if data_processed_exists:
            shutil.copyfile(data_processed_path, f'{data_processed_path}_backup')
            data_processed_path.unlink()
    
        data_processed_fixture_path = "https://storage.googleapis.com/datascience-mlops/taxi-fare-ny/solutions/data_processed_fixture_2009-01-01_2015-01-01_1k.csv"
        os.system(f"curl {data_processed_fixture_path} > {data_processed_path}")
    
        # ACT
>       from taxifare.interface.main_local import train
E       ImportError: cannot import name 'train' from 'taxifare.interface.main_local' (/home/jake/code/jake-humphreys/data-train-at-scale/taxifare/interface/main_local.py)

tests/train_at_scale/test_main_local.py:126: ImportError
----------------------------- Captured stderr call -----------------------------
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100  153k  100  153k    0     0  1029k      0 --:--:-- --:--:-- --:--:-- 1033k
=========================== short test summary info ============================
FAILED tests/train_at_scale/test_main_local.py::TestMainLocal::test_route_preprocess_and_train
FAILED tests/train_at_scale/test_main_local.py::TestMainLocal::test_route_preprocess
FAILED tests/train_at_scale/test_main_local.py::TestMainLocal::test_route_train
=================== 3 failed, 5 passed, 9 warnings in 6.69s ====================
